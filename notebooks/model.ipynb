{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: jiwer==2.3.0 in /opt/miniconda/lib/python3.9/site-packages (2.3.0)\n",
      "Requirement already satisfied: python-Levenshtein==0.12.2 in /opt/miniconda/lib/python3.9/site-packages (from jiwer==2.3.0) (0.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda/lib/python3.9/site-packages (from python-Levenshtein==0.12.2->jiwer==2.3.0) (61.2.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: mlflow==1.26.1 in /opt/miniconda/lib/python3.9/site-packages (1.26.1)\n",
      "Requirement already satisfied: querystring-parser in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (1.2.4)\n",
      "Requirement already satisfied: entrypoints in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (0.4)\n",
      "Requirement already satisfied: sqlalchemy in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (1.3.23)\n",
      "Requirement already satisfied: scipy in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (1.7.1)\n",
      "Requirement already satisfied: alembic in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (1.8.0)\n",
      "Requirement already satisfied: pytz in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (2022.1)\n",
      "Requirement already satisfied: numpy in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (1.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (6.0)\n",
      "Requirement already satisfied: prometheus-flask-exporter in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (0.20.2)\n",
      "Requirement already satisfied: click>=7.0 in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (8.1.3)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (3.1.27)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (4.11.4)\n",
      "Requirement already satisfied: cloudpickle in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (2.1.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (3.19.4)\n",
      "Requirement already satisfied: gunicorn in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (20.1.0)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (0.4.2)\n",
      "Requirement already satisfied: packaging in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (21.3)\n",
      "Requirement already satisfied: docker>=4.0.0 in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (5.0.3)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (0.16.6)\n",
      "Requirement already satisfied: requests>=2.17.3 in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (2.27.1)\n",
      "Requirement already satisfied: pandas in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (1.4.2)\n",
      "Requirement already satisfied: Flask in /opt/miniconda/lib/python3.9/site-packages (from mlflow==1.26.1) (2.1.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/miniconda/lib/python3.9/site-packages (from databricks-cli>=0.8.7->mlflow==1.26.1) (0.8.9)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/miniconda/lib/python3.9/site-packages (from databricks-cli>=0.8.7->mlflow==1.26.1) (1.16.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /opt/miniconda/lib/python3.9/site-packages (from databricks-cli>=0.8.7->mlflow==1.26.1) (2.4.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /opt/miniconda/lib/python3.9/site-packages (from databricks-cli>=0.8.7->mlflow==1.26.1) (3.2.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/miniconda/lib/python3.9/site-packages (from docker>=4.0.0->mlflow==1.26.1) (1.3.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/miniconda/lib/python3.9/site-packages (from gitpython>=2.1.0->mlflow==1.26.1) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/miniconda/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow==1.26.1) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/miniconda/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow==1.26.1) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.9/site-packages (from requests>=2.17.3->mlflow==1.26.1) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda/lib/python3.9/site-packages (from requests>=2.17.3->mlflow==1.26.1) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.9/site-packages (from requests>=2.17.3->mlflow==1.26.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/miniconda/lib/python3.9/site-packages (from requests>=2.17.3->mlflow==1.26.1) (2.0.4)\n",
      "Requirement already satisfied: Mako in /opt/miniconda/lib/python3.9/site-packages (from alembic->mlflow==1.26.1) (1.2.0)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/miniconda/lib/python3.9/site-packages (from Flask->mlflow==1.26.1) (2.1.2)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/miniconda/lib/python3.9/site-packages (from Flask->mlflow==1.26.1) (3.1.2)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /opt/miniconda/lib/python3.9/site-packages (from Flask->mlflow==1.26.1) (2.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda/lib/python3.9/site-packages (from Jinja2>=3.0->Flask->mlflow==1.26.1) (2.0.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/miniconda/lib/python3.9/site-packages (from gunicorn->mlflow==1.26.1) (61.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/miniconda/lib/python3.9/site-packages (from packaging->mlflow==1.26.1) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda/lib/python3.9/site-packages (from pandas->mlflow==1.26.1) (2.8.2)\n",
      "Requirement already satisfied: prometheus-client in /opt/miniconda/lib/python3.9/site-packages (from prometheus-flask-exporter->mlflow==1.26.1) (0.14.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -yrsistent (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -sutil (/opt/miniconda/lib/python3.9/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import keras.losses\n",
    "from keras import constraints, initializers, regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Wrapper\n",
    "from keras.layers import BatchNormalization, TimeDistributed, Bidirectional\n",
    "from keras.layers import LeakyReLU, PReLU, ThresholdedReLU, ELU\n",
    "from keras.layers import (\n",
    "    Convolution2D,\n",
    "    MaxPooling2D,\n",
    "    Convolution1D,\n",
    "    Conv1D,\n",
    "    SimpleRNN,\n",
    "    GRU,\n",
    "    LSTM,\n",
    "    CuDNNLSTM,\n",
    "    CuDNNGRU,\n",
    "    Conv2D,\n",
    ")\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Lambda,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Embedding,\n",
    "    Activation,\n",
    "    GRUCell,\n",
    "    LSTMCell,\n",
    "    SimpleRNNCell,\n",
    ")\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.constraints import max_norm\n",
    "from keras import regularizers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import keras\n",
    "from scipy.fftpack import fft\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from scipy.fftpack import dct\n",
    "from scipy import signal\n",
    "import json\n",
    "import soundfile\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "from random import sample\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from prep import prep\n",
    "\n",
    "# prep = prep()\n",
    "# Audio processing\n",
    "# Neural Network\n",
    "\n",
    "# Setting Random Seeds\n",
    "np.random.seed(95)\n",
    "RNG_SEED = 95\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile #for audio processing\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "!pip install jiwer==2.3.0\n",
    "from jiwer import wer\n",
    "import random\n",
    "!pip install mlflow==1.26.1\n",
    "import mlflow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.insert(0, '../scripts/')\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "import helper\n",
    "from ctc_loss import CTC_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_step = 256\n",
    "ctc = CTC_loss(frame_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logspectrorgam import LogMelSpectrogram\n",
    "def preprocessin_model(sample_rate, fft_size, frame_step, n_mels, mfcc=False):\n",
    "\n",
    "    input_data = Input(name='input', shape=(None,), dtype=\"float32\")\n",
    "    featLayer = LogMelSpectrogram(\n",
    "        fft_size=fft_size,\n",
    "        hop_size=frame_step,\n",
    "        n_mels=n_mels,\n",
    "        \n",
    "        sample_rate=sample_rate,\n",
    "        f_min=0.0,\n",
    "        \n",
    "        f_max=int(sample_rate / 2),\n",
    "    )(input_data)\n",
    "    \n",
    "    x = BatchNormalization(axis=2)(featLayer)\n",
    "    model = Model(inputs=input_data, outputs=x, name=\"preprocessin_model\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file read as csv\n"
     ]
    }
   ],
   "source": [
    "translation_obj = helper.read_obj(\"../data/translation_dict.pkl\")\n",
    "audio_obj = helper.read_obj(\"../data/audio_dict.pkl\")\n",
    "meta_data = helper.read_csv(\"../data/meta_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "      <th>label</th>\n",
       "      <th>channel</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>እኛ ም እ ኮ ፉትቦል ን እንወዳ ለ ን</td>\n",
       "      <td>tr_3933_tr40034</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>አሸናፊ ፈጣን ተጨዋች ነው</td>\n",
       "      <td>tr_1541_tr16042</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>እንስራ ው ተ ሸነቆረ</td>\n",
       "      <td>tr_10369_tr100091</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ጥያቄ ያችን ጆንያ ሙሉ ነው</td>\n",
       "      <td>tr_10067_tr098029</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>ኳስ ጨዋታ ኳስ ነው</td>\n",
       "      <td>tr_342_tr04042</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>2.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>በ አውሮፕላኗ ተመትቶ መውደቅ ሳቢያ ዜጐቻቸው ን ላ ጡት የ ብሪታኒያ ና ...</td>\n",
       "      <td>tr_2566_tr26067</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>20.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>ሁሴን አይዲድ እንደ ገለጹት ኢትዮጵያ ሁኔታዎች ከ ተመቻቹ ላት ሶማሊያ ን...</td>\n",
       "      <td>tr_16_tr01016</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>20.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>ከ ግዛታቸው ዋ ና ከተማ ጋሪ ስ ሆነው በ ስልክ ሚስተር ሞሪስ ከ ስደተኞ...</td>\n",
       "      <td>tr_2212_tr23013</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>20.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>የተ ለቀቁት ምርኮኞች በ አካባቢያቸው ሰላማዊ ኑሮ እንዲ ኖሩ የ ትራንስፖ...</td>\n",
       "      <td>tr_2560_tr26061</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>21.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>የ ትምህርት ደረጃቸው ንና የ አገልግሎት ሁኔታ ቸውን ስን መረምር የሚ ደ...</td>\n",
       "      <td>tr_2565_tr26066</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>22.784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            translation              label  \\\n",
       "4133                           እኛ ም እ ኮ ፉትቦል ን እንወዳ ለ ን    tr_3933_tr40034   \n",
       "1476                                   አሸናፊ ፈጣን ተጨዋች ነው    tr_1541_tr16042   \n",
       "408                                       እንስራ ው ተ ሸነቆረ  tr_10369_tr100091   \n",
       "73                                    ጥያቄ ያችን ጆንያ ሙሉ ነው  tr_10067_tr098029   \n",
       "3574                                       ኳስ ጨዋታ ኳስ ነው     tr_342_tr04042   \n",
       "...                                                 ...                ...   \n",
       "2614  በ አውሮፕላኗ ተመትቶ መውደቅ ሳቢያ ዜጐቻቸው ን ላ ጡት የ ብሪታኒያ ና ...    tr_2566_tr26067   \n",
       "1652  ሁሴን አይዲድ እንደ ገለጹት ኢትዮጵያ ሁኔታዎች ከ ተመቻቹ ላት ሶማሊያ ን...      tr_16_tr01016   \n",
       "2222  ከ ግዛታቸው ዋ ና ከተማ ጋሪ ስ ሆነው በ ስልክ ሚስተር ሞሪስ ከ ስደተኞ...    tr_2212_tr23013   \n",
       "2608  የተ ለቀቁት ምርኮኞች በ አካባቢያቸው ሰላማዊ ኑሮ እንዲ ኖሩ የ ትራንስፖ...    tr_2560_tr26061   \n",
       "2613  የ ትምህርት ደረጃቸው ንና የ አገልግሎት ሁኔታ ቸውን ስን መረምር የሚ ደ...    tr_2565_tr26066   \n",
       "\n",
       "      channel  sample_rate  duration  \n",
       "4133        1         8000     2.048  \n",
       "1476        1         8000     2.048  \n",
       "408         1         8000     2.176  \n",
       "73          1         8000     2.176  \n",
       "3574        1         8000     2.176  \n",
       "...       ...          ...       ...  \n",
       "2614        1         8000    20.352  \n",
       "1652        1         8000    20.736  \n",
       "2222        1         8000    20.992  \n",
       "2608        1         8000    21.120  \n",
       "2613        1         8000    22.784  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_metadata = meta_data.sort_values(by=\"duration\")\n",
    "labels = sorted_metadata['label'].to_list()\n",
    "sorted_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = []\n",
    "for label in labels:\n",
    "    audios.append(audio_obj[label][0])\n",
    "    \n",
    "translations = []\n",
    "for label in labels:\n",
    "    translations.append(translation_obj[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting audio lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = []\n",
    "for label in labels:\n",
    "    audios.append(audio_obj[label][0])\n",
    "    \n",
    "translations = []\n",
    "for label in labels:\n",
    "    translations.append(translation_obj[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pridiction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(output_dim, custom_model, preprocess_model, mfcc=False, calc=None):\n",
    "\n",
    "    input_audios = Input(name='the_input', shape=(None,))\n",
    "    pre = preprocess_model(input_audios)\n",
    "    pre = tf.squeeze(pre, [3])\n",
    "\n",
    "    y_pred = custom_model(pre)\n",
    "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
    "    model.output_length = calc\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(output_dim, cnn_model, custom_model, preprocess_model, mfcc=False, calc=None):\n",
    "\n",
    "    input_audios = Input(name='the_input', shape=(None,))\n",
    "    pre = preprocess_model(input_audios)\n",
    "    pre = tf.squeeze(pre, [3])\n",
    "\n",
    "    cnn_output = cnn_model(pre)\n",
    "\n",
    "    y_pred = custom_model(cnn_output)\n",
    "    model = Model(inputs=input_audios, outputs=y_pred, name=\"model_builder\")\n",
    "    model.output_length = calc\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, audio, tokenizer, int_to_char, actual=None):\n",
    "    \n",
    "    pred_audios = tf.convert_to_tensor([audio])\n",
    "    \n",
    "    y_pred = model.predict(pred_audios)\n",
    "\n",
    "    input_shape = tf.keras.backend.shape(y_pred)\n",
    "    input_length = tf.ones(shape=input_shape[0]) * tf.keras.backend.cast(input_shape[1], 'float32')\n",
    "    prediction = tf.keras.backend.ctc_decode(y_pred, input_length, greedy=False)[0][0]\n",
    "        \n",
    "    pred = K.eval(prediction).flatten().tolist()\n",
    "    pred = [i for i in pred if i != -1]\n",
    "    \n",
    "    predicted_text = tokenizer.decode_text(pred, int_to_char)\n",
    "    \n",
    "    error = None\n",
    "    if actual != None:\n",
    "        error = wer(actual, predicted_text)\n",
    "   \n",
    "    return predicted_text, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample snt: እኛ ም እ ኮ ፉትቦል ን እንወዳ ለ ን\n",
      "encoded snt: [13, 74, 1, 16, 1, 13, 1, 67, 1, 142, 3, 122, 12, 1, 2, 1, 13, 2, 37, 39, 1, 11, 1, 2]\n",
      "decoed snt: እኛ ም እ ኮ ፉትቦል ን እንወዳ ለ ን\n"
     ]
    }
   ],
   "source": [
    "from tokenizer import Tokenizer\n",
    "tokenizer = Tokenizer(translations)\n",
    "int_to_char, char_to_int = tokenizer.build_dict()\n",
    "sample = translations[0]\n",
    "encoded = tokenizer.encode(sample, char_to_int)\n",
    "decoded = tokenizer.decode_text(encoded, int_to_char)\n",
    "\n",
    "print(f\"sample snt: {sample}\")\n",
    "print(f\"encoded snt: {encoded}\")\n",
    "print(f\"decoed snt: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.write_obj(\"../int_to_char.pkl\", int_to_char)\n",
    "helper.write_obj(\"../char_to_int.pkl\", char_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# int to character or character to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_rate = 8000\n",
    "fft_size = 512\n",
    "frame_step = 256\n",
    "n_mels = 128\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 20\n",
    "data_len = len(translations)\n",
    "output_dim = len(char_to_int) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 12:39:56.188468: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-09 12:39:56.188516: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-60-46.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-09 12:39:56.188929: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"preprocessin_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, None)]            0         \n",
      "                                                                 \n",
      " log_mel_spectrogram (LogMel  (None, None, 128, 1)     0         \n",
      " Spectrogram)                                                    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 128, 1)     512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 512\n",
      "Trainable params: 256\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from data_generator import DataGenerator\n",
    "dg = DataGenerator(translations, audios, batch_size, shuffle=True)\n",
    "preprocess_model = preprocessin_model(sample_rate, fft_size, frame_step, n_mels)\n",
    "preprocess_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model2 import simple_rnn_model, CNN_net, BidirectionalRNN2, cnn_rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simple_rnn_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 128)]       0         \n",
      "                                                                 \n",
      " rnn (GRU)                   (None, None, 223)         236157    \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 223)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 236,157\n",
      "Trainable params: 236,157\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "speech_simple_rnn = simple_rnn_model(n_mels, output_dim)\n",
    "speech_simple_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn_speech_model = build_model(output_dim, speech_simple_rnn, preprocess_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_builder, \n",
    "          data_gen,\n",
    "          batch_size = 32,\n",
    "          epochs=20, \n",
    "          verbose=1,\n",
    "          save_path=\"../models/model.h5\",\n",
    "          optimizer=SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
    "          ):    \n",
    "              \n",
    "    model = ctc.add_ctc_loss(model_builder)\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath=save_path, verbose=0)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "    hist = model.fit_generator(generator=data_gen,\n",
    "                               callbacks=[checkpointer],\n",
    "\n",
    "                               epochs=epochs,\n",
    "                               verbose=verbose, \n",
    "                               use_multiprocessing=False)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " preprocessin_model (Functional  (None, None, 128, 1  512        ['the_input[0][0]']              \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, None, 128)   0           ['preprocessin_model[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " simple_rnn_model (Functional)  (None, None, 223)    236157      ['tf.compat.v1.squeeze[0][0]']   \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['input_length[0][0]']           \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ctc (Lambda)                   (None, 1)            0           ['simple_rnn_model[0][0]',       \n",
      "                                                                  'the_labels[0][0]',             \n",
      "                                                                  'lambda[0][0]',                 \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 236,669\n",
      "Trainable params: 236,413\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 34s 656ms/step - loss: 738.5428\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 33s 658ms/step - loss: 683.3772\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 33s 663ms/step - loss: 682.5974\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 33s 658ms/step - loss: 682.2233\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 33s 659ms/step - loss: 681.9722\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 32s 641ms/step - loss: 681.7687\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 33s 658ms/step - loss: 681.5850\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 33s 649ms/step - loss: 681.3881\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 33s 634ms/step - loss: 680.9241\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 33s 648ms/step - loss: 680.7704\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 33s 655ms/step - loss: 680.6139\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 33s 649ms/step - loss: 680.5239\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 33s 658ms/step - loss: 680.4291\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 33s 639ms/step - loss: 680.3298\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 33s 653ms/step - loss: 680.1700\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 33s 655ms/step - loss: 680.1617\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 33s 652ms/step - loss: 680.0152\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 32s 646ms/step - loss: 679.9487\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 33s 662ms/step - loss: 679.9163\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 33s 650ms/step - loss: 679.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f4c43d82c70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlflow.set_experiment('Speech Model-RNN-baseline')\n",
    "# mlflow.tensorflow.autolog()\n",
    "train(simple_rnn_speech_model, dg, epochs=20, save_path=\"../model/simple_rnn_model.h5\",  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 368ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 12:58:05.678197: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"AuthenticAMD\" model: \"241\" frequency: 2800 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 524288 l3_cache_size: 16777216 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual በ ባህል በ ቋንቋ አንድ ናቸው\n",
      "predicted ተአንየንየንየንአንተንተንየንየንተንተንተንየ\n",
      "WER:  1.0\n"
     ]
    }
   ],
   "source": [
    "simple_rnn_speech_model.load_weights(\"../model/simple_rnn_model.h5\")\n",
    "\n",
    "\n",
    "actual_translation = translations[10]\n",
    "sample_test_audio = audios[0]\n",
    "predicted, error = predict(simple_rnn_speech_model, sample_test_audio , tokenizer, int_to_char, actual=actual_translation)\n",
    "\n",
    "print(\"actual\", actual_translation)\n",
    "print(\"predicted\", predicted)\n",
    "print(\"WER: \", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - BiDirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 128)]       0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 250)         128250    \n",
      "                                                                 \n",
      " bn_conv_1d (BatchNormalizat  (None, None, 250)        1000      \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " rnn (SimpleRNN)             (None, None, 400)         260400    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 400)        1600      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 223)        89423     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 223)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 480,673\n",
      "Trainable params: 479,373\n",
      "Non-trainable params: 1,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "speech_cnn_rnn = cnn_rnn_model(n_mels, 250, 4, 1, 'same', 400, output_dim)\n",
    "speech_cnn_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_cnn_rnn_model = build_model(output_dim, speech_cnn_rnn, preprocess_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " preprocessin_model (Functional  (None, None, 128, 1  512        ['the_input[0][0]']              \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_1 (TFOpLa  (None, None, 128)   0           ['preprocessin_model[1][0]']     \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, None, 223)    480673      ['tf.compat.v1.squeeze_1[0][0]'] \n",
      "                                                                                                  \n",
      " the_labels (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 1)            0           ['input_length[0][0]']           \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ctc (Lambda)                   (None, 1)            0           ['model_1[0][0]',                \n",
      "                                                                  'the_labels[0][0]',             \n",
      "                                                                  'lambda_1[0][0]',               \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 481,185\n",
      "Trainable params: 479,629\n",
      "Non-trainable params: 1,556\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 39s 761ms/step - loss: 253.5658\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 39s 753ms/step - loss: 199.8582\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 38s 757ms/step - loss: 194.6649\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 178.3096\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 148.5981\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 127.5699\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 38s 764ms/step - loss: 113.2546\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 38s 773ms/step - loss: 103.8983\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 38s 765ms/step - loss: 97.2641\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 38s 729ms/step - loss: 92.3982\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 38s 748ms/step - loss: 87.7053\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 38s 775ms/step - loss: 84.0777\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 38s 769ms/step - loss: 80.7911\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 38s 772ms/step - loss: 77.7515\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 38s 746ms/step - loss: 75.3177\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 38s 776ms/step - loss: 72.9862\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 38s 773ms/step - loss: 70.7689\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 38s 768ms/step - loss: 68.7641\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 38s 776ms/step - loss: 66.7529\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 38s 773ms/step - loss: 65.0903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f4c43f26550>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(speech_cnn_rnn_model, dg, epochs=20, save_path=\"../model/cnn_rnn_model.h5\",  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 236ms/step\n",
      "actual ራሱ የ ጣሊያን ወራሪ ማስረጃ ነው\n",
      "predicted ራ ታያንና ማረን\n",
      "WER: 1.00\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "actual በ ነገው እ ለት ሁለት የ አዲስ አበባ ባላንጣ ዎች ደርቢ ያቸውን ያ ከ ና ው ና ሉ\n",
      "predicted ናክ ልታለያታላንታጋ ንካና\n",
      "WER: 1.00\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "actual የተባረሩ ኤርትራውያን ድርጅታቸው ተ ሸጦ ወኪሎ ቻቸው ከ አገር እንዲ ወጡ ተወሰነ\n",
      "predicted ተባሩ ኤርታራክተክታ ለው ከገር ወ\n",
      "WER: 1.00\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "actual የ ግብጽ ና የ ሱዱን ሚኒስትሮች ካይሮ መሰባሰባቸው ተገለጠ\n",
      "predicted  ሽዳካ ን\n",
      "WER: 1.00\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "actual ዋንኛ አላማ ዬ ለ ኢትዮጵያ ሰላም ማስገኘት ነው\n",
      "predicted ንል ተፕጵያ ሻላክ\n",
      "WER: 1.00\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "actual እሺ እኔ ትግሬ ነኝ ኢትዮጵያዊ ም ነኝ\n",
      "predicted  ክነ ዮያ ነ\n",
      "WER: 1.00\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "actual እንደ ው ስለ ተጠየቅ ኩበት ሀሳቡ ን እንድታ ገኙ ት ነው\n",
      "predicted ን ለተታ ሳንታገነል\n",
      "WER: 0.91\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "actual የ አንድ ነጥብ አራት ሚሊዮን እድሜ ያለው ቅሬተ አካል ተገኘ\n",
      "predicted የ ነባናል ካሳጋ\n",
      "WER: 0.90\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "actual ፓሊስ የ ህጻናት ን መብት ማስጠበቅ አለ በት ተ ባለ\n",
      "predicted  ስና ታተካለ\n",
      "WER: 1.00\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "actual የ ኢትዮጵያ መንግስት ተስፋ ና ምኞት ችግሩ የመጨረሻ እልባት እንደሚ ሰጠው ነው\n",
      "predicted  ያ ንክታናን መተልለ\n",
      "WER: 1.00\n"
     ]
    }
   ],
   "source": [
    "speech_cnn_rnn_model.load_weights(\"../model/cnn_rnn_model.h5\")\n",
    "for k in range(10):\n",
    "    i = random.randint(0, 3000)\n",
    "    actual_translation = translations[i]\n",
    "    sample_test_audio = audios[i]\n",
    "    predicted, error = predict(speech_cnn_rnn_model, sample_test_audio,\n",
    "                               tokenizer, int_to_char, actual=actual_translation)\n",
    "   \n",
    "    print(\"actual\", actual_translation)\n",
    "    print(\"predicted\", predicted)\n",
    "    print(f\"WER: {error:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining the above two models for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dg = DataGenerator(translations, audios, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model, cnn_shape = CNN_net(n_mels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BidirectionalRNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 1024)]      0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 800)        4560000   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, None, 800)        3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 800)         0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, None, 800)        3843200   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, None, 800)        3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 800)         0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, None, 800)        3843200   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, None, 800)        3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 800)         0         \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, None, 800)        3843200   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, None, 800)        3200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 800)         0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, None, 223)        178623    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 223)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,281,023\n",
      "Trainable params: 16,274,623\n",
      "Non-trainable params: 6,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BI_RNN_2 = BidirectionalRNN2(1024, batch_size=batch_size, output_dim=output_dim)\n",
    "BI_RNN_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_bi_rnn_model = build_model2(output_dim, cnn_model, BI_RNN_2, preprocess_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cnn_bi_rnn_model, dg, epochs=20, save_path=\"../models/cnn_bi_rnn_model.h5\",  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "actual እነዚህ በ ሽሬ አውራጃ የሚገኙ ወረዳ ዎች ናቸው\n",
      "predicted እነዚህ በ ሽሬ የ አውራጄ የሚገኙ ወረዳዎች ናቸው\n",
      "WER: 0.50\n",
      "\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "actual መሪዎቹ ም ታሰሩ ተ ጋዙ ተገደሉ\n",
      "predicted ህመድረች ምንካርሰሩ አጋዙ አጋ ደሉሩ\n",
      "WER: 1.00\n",
      "\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "actual አጀንዳ ችን ያ ቢሆን እዚህ ቦታ ላይ ባል ተገናኘ ን ነበር\n",
      "predicted አጀንዳችን ያቢ ሆን እዚህ ጐታ ላይ ባልተገናኝ ን ነዳር\n",
      "WER: 0.73\n",
      "\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "actual መሬት በ መንግስት መያዙ ለ ኢኮኖሚ እንቅፋት ሆኗል ተ ባለ\n",
      "predicted መሬት በ መንግስት መይያዙ ለ ኢኮለሚንክፋት ሆላል ተባለን\n",
      "WER: 0.60\n",
      "\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "actual አቡነ ጳውሎስ ሜዳሊያ ተሸለሙ\n",
      "predicted አቡና አውሎስት ሄዳለያ ተሸልለሙም\n",
      "WER: 1.00\n",
      "\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "actual በ ዋሽንግተን ዲሲ አዲስ ራዲዮ ጣቢያ ተከፈተ\n",
      "predicted በ ዋሽንግተንእንጂሺ አዲስ ራ አዲወጣ አቢያ ተከፈተ\n",
      "WER: 0.71\n",
      "\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "actual የ ከተማዋ ዋ ና ዋ ና መንገዶች አስቸኳይ ጥገና እየ ተደረገላቸው ነው\n",
      "predicted የከታ መዋ ዋና ዋንና መንግሮች አስቸው ኰጠ ከና እንዲ ገደረታር ናቸው ነው\n",
      "WER: 0.92\n",
      "\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "actual አንድ ብሄራዊ ፌዴሬሽን ማሟላት የሚገባው ን ሁኔታ አላ ሟላ ም\n",
      "predicted አንድ ቤያዊ ፌዴሬሽን ማሟላት የሚ ገባው ሁኔታ ላምሟ ዳም\n",
      "WER: 0.60\n",
      "\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "actual አንተ እባክህ ቁጫጭ እንዴት አስ ፈረምክ ንገረኝ\n",
      "predicted አን ተጋክ ኩሻጅ እንዴት አስፈረንክ ንገረ\n",
      "WER: 0.86\n",
      "\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "actual ጻድቃን ናቸው ተብሎ ይታመን ባቸዋል\n",
      "predicted ጻድቃ ና ቸው ተብሎው ይታመለ ባ ቸዋል\n",
      "WER: 1.40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_bi_rnn_model.load_weights(\"../models/cnn_bi_rnn_model.h5\")\n",
    "for k in range(10):\n",
    "    i = random.randint(0, 3000)\n",
    "    actual_translation = translations[i]\n",
    "    sample_test_audio = audios[i]\n",
    "    predicted, error = predict(cnn_bi_rnn_model, sample_test_audio,\n",
    "                               tokenizer, int_to_char, actual=actual_translation)\n",
    "    print(\"actual\", actual_translation)\n",
    "    print(\"predicted\", predicted)\n",
    "    print(f\"WER: {error:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c2b8563932708ac4f64e3bc4797ea8eb43fc7530baa7f01daadf5b46d7b1fd4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
