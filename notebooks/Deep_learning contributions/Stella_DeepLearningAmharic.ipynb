{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stella_DeepLearningAmharic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Deep learning Model implementation"
      ],
      "metadata": {
        "id": "uxqooBXjug4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing all necessary libraries"
      ],
      "metadata": {
        "id": "IcvRdxepvm1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python_speech_features"
      ],
      "metadata": {
        "id": "ifq33dDw3fji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras import regularizers, callbacks\n",
        "from keras.constraints import max_norm\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Input, Lambda, Dense, Dropout, Flatten, Embedding, Activation, GRUCell, LSTMCell,SimpleRNNCell\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, Conv1D, SimpleRNN, GRU, LSTM, CuDNNLSTM, CuDNNGRU, Conv2D\n",
        "from keras.layers import LeakyReLU, PReLU, ThresholdedReLU, ELU\n",
        "from keras.layers import BatchNormalization, TimeDistributed, Bidirectional\n",
        "from keras.layers import Wrapper\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.utils import np_utils\n",
        "from keras import constraints, initializers, regularizers\n",
        "import keras.losses\n"
      ],
      "metadata": {
        "id": "uL-Mb7utuw2X"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwJOyU_R0F4h",
        "outputId": "824b16d3-86af-4f6b-a456-4f6cc5c07076"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "os.chdir(\"/content/drive/My Drive/AMHARIC\")\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9uy7cAZ0PAW",
        "outputId": "0d6073e3-f7b8-4537-ac2c-653a476001f9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['README.md',\n",
              " 'data',\n",
              " 'kaldi-script',\n",
              " 'lang',\n",
              " 'lm',\n",
              " 'models',\n",
              " 'model_1.png',\n",
              " 'valid_corpus.json',\n",
              " 'train_corpus.json',\n",
              " '__pycache__',\n",
              " 'test_corpus.json']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Importing helper scripts to google collab"
      ],
      "metadata": {
        "id": "D_r2XI_4wmPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "py_file_location = \"/content/drive/My Drive\"\n",
        "sys.path.append(os.path.abspath(py_file_location))"
      ],
      "metadata": {
        "id": "BjJ_z-250b4z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import prep\n",
        "import create_desc_json\n",
        "import AudioGenerator"
      ],
      "metadata": {
        "id": "4uZ3QAXN1P5X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "95225f53-fcd5-43db-c89e-de24fe1cd1c2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b41efdc91e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_desc_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prep'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Defining model 0"
      ],
      "metadata": {
        "id": "wJEMBnT1xNsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN "
      ],
      "metadata": {
        "id": "BDqNcmH6x5i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regular_rnn_model(input_dim, output_dim=29):\n",
        "    # Input\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "    # Recurrent layer\n",
        "    simp_rnn = GRU(output_dim, return_sequences=True, \n",
        "                 implementation=2, name='rnn')(input_data)\n",
        "    # Softmax Activation Layer\n",
        "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
        "    # Specifying the model\n",
        "    model = Model(inputs=input_data, outputs=y_pred)\n",
        "    model.output_length = lambda x: x\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "metadata": {
        "id": "vzy0aR5ExQkE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = regular_rnn_model(input_dim=161)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD4_062GxSf_",
        "outputId": "d589a449-d4aa-4f98-c828-1bf1714b80cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " the_input (InputLayer)      [(None, None, 161)]       0         \n",
            "                                                                 \n",
            " rnn (GRU)                   (None, None, 29)          16704     \n",
            "                                                                 \n",
            " softmax (Activation)        (None, None, 29)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,704\n",
            "Trainable params: 16,704\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "metadata": {
        "id": "jwnHs2-w5Xnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from prep import prep\n",
        "from AudioGenerator import AudioGenerator\n",
        "audio_gen = AudioGenerator(spectrogram=True)"
      ],
      "metadata": {
        "id": "d8Ikg24J5gGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_gen.train_model(input_to_softmax=model_0, \n",
        "            pickle_path='model_0.pickle', \n",
        "            save_model_path='model_0.h5',\n",
        "            spectrogram=True,\n",
        "           ) "
      ],
      "metadata": {
        "id": "guMNLYnf_3KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bidirectional RNN"
      ],
      "metadata": {
        "id": "FLlnGsfa7DVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def brnn_tdd_model(input_dim, units, activation, output_dim=29):\n",
        "    # Input\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "    # Bidirectional recurrent layer\n",
        "    brnn = Bidirectional(LSTM(units, activation=activation, \n",
        "        return_sequences=True, implementation=2, name='brnn'))(input_data)\n",
        "    # TimeDistributed Dense layer\n",
        "    time_dense = TimeDistributed(Dense(output_dim))(brnn)\n",
        "    # Softmax activation layer\n",
        "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
        "    # Specifying the model\n",
        "    model = Model(inputs=input_data, outputs=y_pred)\n",
        "    model.output_length = lambda x: x\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "metadata": {
        "id": "80bGNoRxAZUn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = brnn_tdd_model(input_dim=161, units=200, activation='relu') # 161 for Spectrogram/13 for MFCC"
      ],
      "metadata": {
        "id": "WZya_Pbd7Okd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_gen.train_model(input_to_softmax=model_2, \n",
        "            pickle_path='model_2.pickle', \n",
        "            save_model_path='model_2.h5', \n",
        "            spectrogram=True)"
      ],
      "metadata": {
        "id": "RwEBTaIB7WXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NriejW_H7mNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_deep_brnn_tdd_model(input_dim, filters, activation, kernel_size, conv_stride,\n",
        "    conv_border_mode, recur_layers, units, output_dim=29):\n",
        "    # Input\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "    # Convolutional layer\n",
        "    conv_1d = Conv1D(filters, kernel_size, \n",
        "                     strides=conv_stride, \n",
        "                     padding=conv_border_mode,\n",
        "                     activation=activation,\n",
        "                     name='conv1d')(input_data)\n",
        "    # Batch normalization\n",
        "    bn_cnn = BatchNormalization()(conv_1d)\n",
        "    # Bidirectional recurrent layer\n",
        "    brnn = Bidirectional(GRU(units, activation=activation, \n",
        "        return_sequences=True, name='brnn'))(bn_cnn)\n",
        "    # Batch normalization \n",
        "    bn_rnn = BatchNormalization()(brnn)\n",
        "    # Loop for additional layers\n",
        "    for i in range(recur_layers - 1):\n",
        "        name = 'brnn_' + str(i + 1)\n",
        "        brnn = Bidirectional(GRU(units, activation=activation, \n",
        "        return_sequences=True, implementation=2, name=name))(bn_rnn)\n",
        "        bn_rnn = BatchNormalization()(brnn)\n",
        "    # TimeDistributed Dense layer\n",
        "    time_dense = TimeDistributed(Dense(output_dim))(bn_rnn)\n",
        "    # Softmax activation layer\n",
        "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
        "    # Specifying the model\n",
        "    model = Model(inputs=input_data, outputs=y_pred)\n",
        "    model.output_length = lambda x: audio_gen.cnn_output_length(\n",
        "        x, kernel_size, conv_border_mode, conv_stride)\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "metadata": {
        "id": "X2KuASt27kKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = cnn_deep_brnn_tdd_model(input_dim=161, # 161 for Spectrogram/13 for MFCC\n",
        "                                  filters=200,\n",
        "                                  activation='relu',\n",
        "                                  kernel_size=11, \n",
        "                                  conv_stride=2,\n",
        "                                  conv_border_mode='valid',\n",
        "                                  recur_layers=2,\n",
        "                                  units=200)"
      ],
      "metadata": {
        "id": "YoJoCoJr7sQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_gen.train_model(input_to_softmax=model_3, \n",
        "            pickle_path='model_3.pickle', \n",
        "            save_model_path='model_3.h5', \n",
        "            spectrogram=True) # True for Spectrogram/False for MFCC"
      ],
      "metadata": {
        "id": "Kr5FLie6_K-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction"
      ],
      "metadata": {
        "id": "Qinj-3hm8dJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(data_gen, index, partition, model, verbose=True):\n",
        "    \"\"\" Print a model's decoded predictions\n",
        "    Params:\n",
        "        data_gen: Data to run prediction on\n",
        "        index (int): Example to visualize\n",
        "        partition (str): Either 'train' or 'validation'\n",
        "        model (Model): The acoustic model\n",
        "    \"\"\"\n",
        "    audio_path,data_point,transcr,prediction = predict_raw(data_gen, index, partition, model)\n",
        "    output_length = [model.output_length(data_point.shape[0])]\n",
        "    pred_ints = (K.eval(K.ctc_decode(\n",
        "                prediction, output_length, greedy=False)[0][0])+1).flatten().tolist()\n",
        "    predicted = ''.join(int_sequence_to_text(pred_ints)).replace(\"<SPACE>\", \" \")\n",
        "    wer_val = wer(transcr, predicted)\n",
        "    if verbose:\n",
        "        display(Audio(audio_path, embed=True))\n",
        "        print('Truth: ' + transcr)\n",
        "        print('Predicted: ' + predicted)\n",
        "        print(\"wer: %d\" % wer_val)\n",
        "    return wer_val"
      ],
      "metadata": {
        "id": "ti9kuaTd8e5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_raw(data_gen, index, partition, model):\n",
        "    \"\"\" Get a model's decoded predictions\n",
        "    Params:\n",
        "        data_gen: Data to run prediction on\n",
        "        index (int): Example to visualize\n",
        "        partition (str): Either 'train' or 'validation'\n",
        "        model (Model): The acoustic model\n",
        "    \"\"\"\n",
        "\n",
        "    if partition == 'validation':\n",
        "        transcr = data_gen.valid_texts[index]\n",
        "        audio_path = data_gen.valid_audio_paths[index]\n",
        "        data_point = data_gen.normalize(data_gen.featurize(audio_path))\n",
        "    elif partition == 'train':\n",
        "        transcr = data_gen.train_texts[index]\n",
        "        audio_path = data_gen.train_audio_paths[index]\n",
        "        data_point = data_gen.normalize(data_gen.featurize(audio_path))\n",
        "    else:\n",
        "        raise Exception('Invalid partition!  Must be \"train\" or \"validation\"')\n",
        "        \n",
        "    prediction = model.predict(np.expand_dims(data_point, axis=0))\n",
        "    return (audio_path,data_point,transcr,prediction)\n",
        "def int_sequence_to_text(int_sequence):\n",
        "  \"\"\" Convert an integer sequence to text \"\"\"\n",
        "  text = []\n",
        "  for c in int_sequence:\n",
        "      ch = index_map[c]\n",
        "      text.append(ch)\n",
        "  return text\n",
        "# Code adapted from https://martin-thoma.com/word-error-rate-calculation/\n",
        "def wer(r, h):\n",
        "    \"\"\"\n",
        "    Calculation of WER with Levenshtein distance.\n",
        "\n",
        "    Works only for iterables up to 254 elements (uint8).\n",
        "    O(nm) time ans space complexity.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    r : list\n",
        "    h : list\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> wer(\"who is there\".split(), \"is there\".split())\n",
        "    1\n",
        "    >>> wer(\"who is there\".split(), \"\".split())\n",
        "    3\n",
        "    >>> wer(\"\".split(), \"who is there\".split())\n",
        "    3\n",
        "    \"\"\"\n",
        "    # initialisation\n",
        "    import numpy\n",
        "    d = numpy.zeros((len(r)+1)*(len(h)+1), dtype=numpy.uint8)\n",
        "    d = d.reshape((len(r)+1, len(h)+1))\n",
        "    for i in range(len(r)+1):\n",
        "        for j in range(len(h)+1):\n",
        "            if i == 0:\n",
        "                d[0][j] = j\n",
        "            elif j == 0:\n",
        "                d[i][0] = i\n",
        "\n",
        "    # computation\n",
        "    for i in range(1, len(r)+1):\n",
        "        for j in range(1, len(h)+1):\n",
        "            if r[i-1] == h[j-1]:\n",
        "                d[i][j] = d[i-1][j-1]\n",
        "            else:\n",
        "                substitution = d[i-1][j-1] + 1\n",
        "                insertion    = d[i][j-1] + 1\n",
        "                deletion     = d[i-1][j] + 1\n",
        "                d[i][j] = min(substitution, insertion, deletion)\n",
        "\n",
        "    return d[len(r)][len(h)]\n",
        "def calculate_wer(model, model_name, data_gen, partition, length):\n",
        "    start = time.time()\n",
        "    def wer_single(i):\n",
        "        wer = predict(data_gen, i, partition, model, verbose=False)\n",
        "        if (i%100==0) and i>0:\n",
        "            print(\"processed %d in %d minutes\" % (i, ((time.time() - start)/60)))\n",
        "        return wer\n",
        "    wer = list(map(lambda i: wer_single(i), range(1, length)))\n",
        "    print(\"Total time: %f minutes\" % ((time.time() - start)/60))\n",
        "    filename = 'models/' + model_name + '_' + partition + '_wer.pickle'\n",
        "    with open(filename, 'wb') as handle:\n",
        "        pickle.dump(wer, handle)\n",
        "    return wer\n",
        "def load_wer(model_name, partition):\n",
        "    filename = 'models/' + model_name + '_' + partition + '_wer.pickle'\n",
        "    return pickle.load(open(filename, \"rb\"))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cVWWlRDz8tMc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(audio_gen,14, 'train', model)\n",
        "_,_,_,raw_pred = predict_raw(audio_gen,14, 'train', model)\n",
        "raw_pred_char = np.vstack([sorted(char_map.keys(), key=lambda k: char_map[k]) + ['BLANK'], raw_pred[0]])"
      ],
      "metadata": {
        "id": "6njAceQK86Jy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}